# Классификация
## Метрический классификатор

$$ X = {\bf{x_i}}$$
$$ Y = {y_i}$$
$$\bf{x_i} \rightarrow y$$

## Метрическая функция

$$d:X^2 \rightarrow \bf{R}$$

### Свойства
- Симетричность $d(x,\ y) = d(y,\ y)$
- $d(x, y) = 0 <=> x = y$

## Гепотиза локальности
## Метод ближайшего соседа

$$(1 - NN, k - NN)$$
### Евклидова метрика

$$L_2(x, b) = \sqrt{\sum\limits_{i} (a_i - b_i)^2}$$
$$L_1(x, b) = \sqrt{\sum\limits_{i} \big|a_i - b_i\big|}$$

### Метрика Хэминга

$$H(a,\ b) = \sum\limits_i d(a_i,\ b_i)$$

### Расстояние Либенштейна

LV = количеству операций вставки и удаления, чтобы из строки **a** получить строку **b**

### Косинусное расстояние

$$L = 1 - \frac{(a, b)}{\big|a\big|\big|b\big|}$$

### Метрика Махалонобиса

$$d = \sqrt{X^T S^{-1} X}$$
$S$ -- матрица ковариации

## Алгоритмы

1. Сохранение границы.  Переход от (k - NN) классификатора к (1 - NN) классификатору

Def: Точка выброс (outlier), тогда и только тогда она не склассифицируется с помощью кроссвалидации, с сохранением границы.

Def: Усвоеные точки (absorted)

### Алгоритм Харфа(Harf)

Жадник на основании функции граничности
#### Функция граничности

$$\alpha(x) = \frac{\big|\big|x^\prime - y\big|\big|}{\big|\big|x - y\big|\big|}$$

- $y = argmin{\ d(x, y)},\ f(y) \neq f(x)$ 
- $x^\prime = argmin{\ d(x^\prime, y)},\ f(x^\prime) = f(x)$ 

#### KD - деревья
#### Хэширование
- LPH-hash
- LSH-hash
- ?? Фильтр Блума
#### soft max
#### Метод ближайших компонент (Nearest Component Analysis NCA)
#### Метод (Large Margin NN)

Найти такой афинное преобразование, что K ближайших точек  нашего класса находятся ближе, чем ближайшая точка не нашего класса.